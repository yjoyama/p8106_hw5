---
title: "Homework5"
author: "Yuki Joyama"
date: "2024-04-28"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, message = F, warning = F)

library(tidyverse)
library(ggplot2)
library(rsample) 
library(caret)
library(kernlab)
library(ISLR)

# setup plot theme
theme_set(
  theme_bw() +
    theme(legend.position = "top")
  )
```

# 1 Support Vector Machine
```{r dataprep}
# read csv files 
df_auto = read_csv("./auto.csv") 
str(df_auto)

# partition (training:test=70:30)
set.seed(100)
data_split = initial_split(df_auto, prop = .70)
train = training(data_split)
test = testing(data_split)
```

## a
Fit a support vector linear classifier to the training data
```{r}
ctrl <- trainControl(method = "cv")

set.seed(100)

svml.fit <- train(
  mpg_cat ~ cylinders + displacement + horsepower + weight + acceleration + year + origin,
  data = train,
  method = "svmLinear",
  tuneGrid = data.frame(C = exp(seq(-4, 5, len = 50))),
  trControl = ctrl
)

plot(svml.fit, highlight = TRUE, xTrans = log)
svml.fit$finalModel
```

I implemented the cross validation to determine the tuning parameter C. In this case, the best parameter C was `r round(svml.fit$bestTune, 3)`.  
The misclassification error rate using the training data is **0.0912**.

```{r}
# test error
test.pred <- predict(svml.fit, newdata = test, type = "raw")

confusionMatrix(
  data = test.pred,
  reference = as.factor(test$mpg_cat)
)
```

The test error rate is 1 - 0.9237 = **0.0763**  

## b
Now, let's fit a support vector machine with a radial kernel to the training data
```{r}
svmr.grid <- expand.grid(
  C = exp(seq(-4, 5, len = 50)),
  sigma = exp(seq(-10, 2, len = 20))
)

set.seed(100)

svmr.fit <- train(
  mpg_cat ~ cylinders + displacement + horsepower + weight + acceleration + year + origin,
  data = train,
  method = "svmRadialSigma",
  tuneGrid = svmr.grid,
  trControl = ctrl
)

svmr.fit$finalModel

myCol <- rainbow(25)
myPar <- list(
  superpose.symbol = list(col = myCol),
  superpose.line = list(col = myCol)
)

plot(svmr.fit, highlight = TRUE, par.settings = myPar)
```

The best tuning parameters selected by the CV are C = `r round(svmr.fit$bestTune[2], 3)` and sigma = `r round(svmr.fit$bestTune[1], 3)`.  
The training error rate is **0.0876**.


```{r}
# test error
test.pred <- predict(svmr.fit, newdata = test, type = "raw")

confusionMatrix(
  data = test.pred,
  reference = as.factor(test$mpg_cat)
)
```

The test error rate is 1 - 0.9237 = **0.0763**

# 2 Hierarchical Clustering 
```{r}
# data prep
data("USArrests")

df_arrest = USArrests |> 
  janitor::clean_names()

str(df_arrest)
```

# a

